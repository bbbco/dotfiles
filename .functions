# Use .... to cd
for i in {1..9};do c=;d=;for u in `eval echo {1..$i}`;do c="$c../";d="$d..";eval "$d(){ cd $c;}"; eval "$d.(){ cd $c;}";done;done

# jsoncat
function jsoncat(){ cat "${1}" | python -mjson.tool; }

# json2yaml
function json2yaml(){
    python -c '
import sys, json, yaml
with open(sys.argv[1]) as f:
    print yaml.safe_dump(json.load(f), default_flow_style=False)
        ' $@
}

function yaml2json(){
    python -c '
import yaml, json, sys
with open(sys.argv[1]) as f:
    json.dumps(yaml.load(f), sort_keys=True, indent=2)
        ' $@
}

# Epoch Converter
function epoch2time() ( 
    function e2t() {
        if [ ${#EPOCH} -ge 13 ]; then
            EPOCH=${1:0: -3}
        else
            EPOCH=${1}
        fi
        FORMAT=${*:2}
        date -d "@${EPOCH}" ${FORMAT}
    }
    if [ ${1} == "-" ]; then
        STDIN=($(</dev/stdin))
        for S in ${STDIN}; do
            e2t ${S} ${*:2}
        done
    else
        e2t ${1} ${*:2}
    fi
)
function upoch2time() { TZ='UTC-0' epoch2time ${*}; }
function time2epoch() { echo "$(date -d "${1}" +%s)000"; }
function time2upoch() { echo "$(TZ='UTC-0' date -d "${1}" +%s)000"; }
function istdate() { TZ='Asia/Kolkata' date ${@} }
function utcdate() { date -u ${@} }
function since() { 
    first=$(date -d "${1}" +%s)
    second=$(date -d "${2}" +%s)
    secs=$(( ${second} - ${first} ))
    if [ ${secs} -lt 0 ]; then
        secs=$(( ${secs} * -1 ))
    fi
    day=$(( 60*60*24 ))
    days=$(( $secs / ${day}  ))
    secs=$(( ${secs} - ( ${days} * ${day} )  ))
    hour=$(( 60*60  ))
    hours=$(( ${secs} / ${hour} ))
    secs=$(( ${secs} - ( ${hours} * ${hour} ) ))
    minute=$(( 60  ))
    minutes=$(( ${secs} / ${minute} ))
    secs=$(( ${secs} - ( ${minutes} * ${minute} ) ))
    echo "First: $(date -d @${first}) ; Second: $(date -d @${second})"
    echo "${days} days, ${hours} hours, ${minutes} minutes, ${secs} seconds"
}

# Only show hidden files
function hidden() { 
    ls -a "$@" | grep '^\.'
}

# Testing Dir
function td() {
    if [ -n "$1" ]; then
        DATE="$(date -d ${1} +%Y%m%d)"
    else
        DATE="$(date +%Y%m%d)"
    fi
    TD="${HOME}/digitalsmiths/testing/${DATE}"
    if [ ! -d "${TD}" ]; then
        mkdir "${TD}"
    fi
    echo "${TD}"
}

function _td() {
    TD=$(td ${@})
    cd ${TD}
}

# Send alert when previous command fails
function notify-on-fail() {
    if [ "${PIPESTATUS[${#PIPESTATUS[@]}-1]}" != "0" ]; then notify-send "ERROR!" ; fi;
}

# SSH
function sshos-colored() {
    ct -Ge "#run {ssh} {ssh -i /home/bgoad/.ssh/pem_keys/openstack.pem -o \"UserKnownHostsFile /dev/null\" -o StrictHostKeyChecking=no -o CanonicalizeHostname=yes -o CanonicalDomains=digitalsmithsdev.net -l root ${@}}";
}

function sshos() {
    ssh -i /home/bgoad/.ssh/pem_keys/openstack.pem -o "UserKnownHostsFile /dev/null" -o StrictHostKeyChecking=no -o CanonicalizeHostname=yes -o CanonicalDomains=digitalsmithsdev.net -l root ${@};
}

function sshaws() {
    ssh -i /home/bgoad/.ssh/pem_keys/bgoad-aws.pem -o "UserKnownHostsFile /dev/null" -o StrictHostKeyChecking=no -o CanonicalizeHostname=yes -o CanonicalDomains=digitalsmithsdev.net -l root ${@};
}

function sshdqs() {
    ssh -i /home/bgoad/.ssh/pem_keys/devqa-scalability.pem -o "UserKnownHostsFile /dev/null" -o StrictHostKeyChecking=no -o CanonicalizeHostname=yes -o CanonicalDomains=digitalsmithsdev.net -l root ${@};
}

knife-replace-db(){

#    DBI="$(grep '"id":' "${1}" | cut -d\" -f4)"
#    DB=$(echo "${1}" | sed -e 's/data_bags\/\([^\/]*\)(-dev)?\/.*/\1/')

        DB="$(echo "${1}" | sed -e 's/data_bags\///' -e 's/-dev//' -e 's:/: :g' -e 's/\.json//')"
        FILE="${2-${1}}"
        echo "knife data bag show ${DB} -F json > "${FILE}""
#    knife data bag show ${DB} -F json > "${FILE}"
}

function kdbd-push() {
    if [ -z "${1}" ]; then
        echo "No file passed!"
        return 1
    fi
    kdbd ${1} || { echo "Fix issue!"; return 1; } && {
        git add ${1}
        git commit -m "${1} update"
        git reset HEAD chef-cookbooks
        git stash
        git pull
        git push
        git stash pop
    }
}


function decode_url() {
    ruby -e "require 'uri'; puts URI.decode_www_form_component(\"${1}\")"
}

function cpswap() {
    F=${1}.tmp
        mv "${1}" "${F}"
        mv "${2}" "${1}"
        mv "${F}" "${2}"
}

function bak() {
    cp ${1} ${1}.bak
}

# Git
function git_branch() {
    git symbolic-ref -q --short HEAD || git describe --tags --exact-match
}

function is_git() {
    [ -d .git ] || git rev-parse --git-dir > /dev/null 2>&1
}

function git_root() {
    git rev-parse --show-toplevel
}

# FFS Builds
function ffs_path() {
    is_git && export FFS_HOME=$(git_root) || export FFS_HOME=~/digitalsmiths/git/product/ffs
}

function ffs_docker_path() {
    ffs_path && echo "${FFS_HOME}/ffs-server/target/docker"
}

function ffs_mvn_build() {
    local orig_dir=$(pwd)
        ffs_path
        cd ${FFS_HOME}
    mvn -B -U -TC1 clean install -DskipTests -Pbuild-rpms,docker
        cd ${orig_dir}
    ffs_docker_up
}

function delete_from_history() {
    if [ -z ${@} ]; then
        echo "No idea what you're trying to cover up!"
    fi
    LC_ALL=C sed -i "/${@}/d" ${HISTFILE}
}

function emr_logs() {
    if [ "${#*}" -ge 2 ]; then
        jobid="${1}"
        stepid="${2}"
        s3_path="s3://ds-dwh-qa/${3:-qa-si-ec2-insight-0}/emr/logs/${jobid}/steps/${stepid}"
    elif [ "${#*}" -eq 1 ]; then
        s3_path="${1%/}"
        jobid=$(echo ${s3_path} | rev | cut -d \/ -f 3 | rev )
        stepid=$(echo ${s3_path} | rev | cut -d \/ -f 1 | rev )
    fi
    if [ -z "${s3_path}" ]; then
        echo "No path found! Please pass an s3 path or cluster id and step ids!"
        return 1
    fi
    _td
    mkdir -p "${jobid}/${stepid}"
    cd "${jobid}/${stepid}"
    aws s3 cp ${s3_path} . --recursive
}
